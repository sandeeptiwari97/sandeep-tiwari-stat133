---
title: 'Lab 11: Regular Expressions'
author: "Sandeep Tiwari"
date: "11/17/2017"
output: github_document
---

> ### Learning Objectives
>
> - Work with the package `"stringr"`
> - String manipulation
> - More regular expressions
> - A bit of data cleaning
> - Making some maps

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.path = 'lab11-images/')
#install.packages('ggmap')
library(ggmap)
```

------

## Motivation

So far we've been working with data sets that have been already cleaned, and 
can be imported in R ready to be analyzed.

Today we are going to start dealing with "messy" datasets. Most real life data 
sets require a pre-processing phase, and most of the time in any data analysis
project will be spent on getting the data in the right shape. So it is 
extremely important that you gain skills to help you clean raw data.

While you work on this lab you may want to look at the [regex cheatsheet](https://github.com/ucb-stat133/stat133-fall-2017/blob/master/cheat-sheets/regular-expressions-cheatsheet.pdf)


### Mobile Food Schedule Data

The data set is on the github repo:
[https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2017/master/data/mobile-food-sf.csv](https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2017/master/data/mobile-food-sf.csv)

The original source comes from the SF Open Data website:
[https://data.sfgov.org/Economy-and-Community/Mobile-Food-Schedule/jjew-r69b](https://data.sfgov.org/Economy-and-Community/Mobile-Food-Schedule/jjew-r69b)

Download a copy of the file to your working directory:

```{r eval = FALSE}
github <- "https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2017/master/"
datafile <- "data/mobile-food-sf.csv"
download.file(paste0(github, datafile), destfile = "mobile-food-sf.csv")
```

Once you've downloaded the data file, you can read it in R:

```{r eval = FALSE}
dat <- read.csv('mobile-food-sf.csv', stringsAsFactors = FALSE)
```

```{r echo = FALSE}
dat <- read.csv('mobile-food-sf.csv', stringsAsFactors = FALSE)
```

The variables are:

- `DayOfWeekStr`
- `starttime`
- `endtime`
- `PermitLocation`
- `optionaltext`
- `ColdTruck`
- `Applicant`
- `Location`


### Package `"stringr"`

R has a set of built-in functions for manipulating strings. But there is also
the package `"stringr"` that provides more functionality and a more user 
friendly syntax. 

```{r}
# install.packages("stringr")
library(stringr)
```


## Changing Times

Let's begin processing the values in column `starttime`. The goal is to obtain 
new times in 24 hr format. For example, a starting time of `10AM` will be 
transformed to `10:00`. Likewise, a starting time of `1PM` will be
transformed to `13:00`.

We are going to be manipulating character strings. Hence, I recommend to start working on a small subset of values. Figure out how to get the
answers working on this subset, and then generalize to the entire data set.

Consider the first starting time that has a value of `10AM`. To get a better feeling of string manipulation, let's create a toy string with this value:

```{r}
# toy string
time1 <- '10AM'
```


### Function `str_sub()`

To get the time and period values, you can use `str_sub()`:

```{r}
# hour
str_sub(time1, start = 1, end = 2)

# period
str_sub(time1, start = 3, end = 4)
```

__Your turn__: What about times where the hour has just one digit? For example: `9AM`, or `8AM`? Create the following vector `times` and try to subset the hour and the periods with `str_sub()` 

```{r}
times <- c('12PM', '10AM', '9AM', '8AM')

# subset time
str_sub(times, start = 1, end = -3)

# subset period
str_sub(times, start = -2)

#
```

The nice thing about `str_sub()` is that it allows you to specify negative values for the `start` and `end` positions. Run the command below and see what happens:

```{r eval = FALSE}
# period
str_sub(times, start = -2)
```


### Function `str_replace()`

The tricky part with the vector `times` is the extraction of the hour. One solution is to "remove" the
characters `AM` or `PM` from each time. You can do this with the substitution
function `str_replace()`:

```{r}
str_replace(times, pattern = 'AM|PM', replacement = '')
```


### Your Turn

So far you've managed to get the hour value and the period. Notice that 
you still need to convert the hours as numeric vectors:

```{r}
hours <- as.numeric(str_replace(times, pattern = 'AM|PM', replacement = ''))
periods <- str_sub(times, start = -2)
```

- Transform the hours into 24 hr values. Write R code to
create a vector `start24` that contains the hour in 24hr scale.

```{r}
# your vector start24
start24 <- c()
for(i in 1:length(hours)) {
  if (periods[i] == 'AM') {
    start24[i] = paste((hours[i]+12)%%12, ':00', sep = "")
  } else {
    start24[i] = paste((hours[i]), ':00', sep = "")
  }
}
start24
```


- Add two columns `start` and `end` to the data frame `dat`, containing
the starting and ending hour respectively (columns must be `"numeric"`).

```{r}
# add 'start' hours
for(i in 1:nrow(dat)) {
  if (str_sub(dat$starttime[i], start = -2) == 'PM') {
    dat$start[i] = as.numeric(str_replace(dat$starttime[i], pattern = "AM|PM", replacement = ""))+12
  } else {
    dat$start[i] = as.numeric(str_replace(dat$starttime[i], pattern = "AM|PM", replacement = ""))%%12
  }
}

# add 'end' hours
for(i in 1:nrow(dat)) {
  if (str_sub(dat$endtime[i], start = -2) == 'PM') {
    dat$end[i] = as.numeric(str_replace(dat$starttime[i], pattern = "AM|PM", replacement = ""))+12
  } else {
    dat$end[i] = as.numeric(str_replace(dat$endtime[i], pattern = "AM|PM", replacement = ""))%%12
  }
}
dat$start = strtoi(dat$start)
dat$end = strtoi(dat$end)
```


- With the starting and ending hours, calculate the duration, and add one
more column `duration` to the data frame `dat`:

```{r}
# add 'duration'
dat$duration = abs(dat$end - dat$start)
```


-----

## Latitude and Longitude Coordinates

Another interesting column in the data is `Location`. If you look at this 
column, you will see values like the following string `loc1`

```{r}
loc1 <- "(37.7651967350509,-122.416451692902)"
```

The goal is to split `Location` into latitude and longitude. The first value
corresponds to latitude, while the second value corresponds to longitude.

First we need to remove the parenthesis. The issue here is that the characters
`(` and `)` have special meanings; recall they are metacharacters. So you need 
to __escape__ in R them by pre-appending two backslashes: `\\(` and `\\)`

```{r}
# "remove" opening parenthesis 
str_replace(loc1, pattern = '\\(', replacement = '')

# "remove" closing parenthesis
str_replace(loc1, pattern = '\\)', replacement = '')
```

You can also combine both patterns in a single call. But be careful:

```{r}
str_replace(loc1, pattern = '\\(|\\)', replacement = '')
```

`str_replace()` replaces only the first occurrence of `(` or `)`. However, the
location values contain both opening and closing parentheses. To replace them
all, you have to use `str_replace_all()`

```{r}
str_replace_all(loc1, pattern = '\\(|\\)', replacement = '')
```

Now we need to get rid of the comma `,`. You could replace it with an empty
string, but then you will end up with one long string like this:

```{r}
lat_lon <- str_replace_all(loc1, pattern = '\\(|\\)', replacement = '')

str_replace(lat_lon, pattern = ',', replacement = '')
```

Instead of replacing the comma, what we need to use is `str_split()`

```{r}
# string split in stringr
str_split(lat_lon, pattern = ',')
```

Notice that `str_split()` returns a list.


### Manipulating more location values

Let's define a vector with more location values, so we can start generalizing
our code:

```{r}
locs <- c(
  "(37.7651967350509,-122.416451692902)",
  "(37.7907890558203,-122.402273431333)",
  "(37.7111991003088,-122.394693339395)",
  "(37.7773000262759,-122.394812784799)",
  NA
)
```

- create a list `lat_lon` containing the latitude and the longitude values of `locs`
```{r}
lat_lon <- str_split(str_replace_all(locs, pattern = '\\(|\\)', replacement = ""), pattern = ",")
lat_lon
```

Assuming that you have `lat_lon`, to retrieve the latitude and longitude values, you can use the `lapply()` 
function, and then specify an _anonymous_ function to get the first element 
(for the latitude): 

```{r}
lat <- lapply(lat_lon, function(x) x[1])
```

### Your Turn

Create a list `lon` by using `lapply()` with an anonymous 
function to extract longitude value (i.e. the second element):

```{r echo = FALSE}
lat <- as.numeric(sapply(lat_lon, function(x) x[1]))
lon <- as.numeric(sapply(lat_lon, function(x) x[2]))
lat
```

To convert from list to a vector, use `unlist()`

```{r warning=FALSE}
latitute <- as.numeric(unlist(lat))
longitude <- as.numeric(unlist(lon))
```

Add two more columns: `lat` and `lon` to the data frame `dat`

```{r}
# your code
dat$lat <- unlist(lat)
dat$lon <- unlist(lon)
dat
```

```{r echo = FALSE}
lat_lon <- str_split(
  str_replace_all(dat$Location, pattern = '\\(|\\)', replacement = ''), 
  pattern = ',')

lat <- lapply(lat_lon, function(x) x[1])
lon <- lapply(lat_lon, function(x) x[2])

dat$lat <- as.numeric(unlist(lat))
dat$lon <- as.numeric(unlist(lon))

```

-----

## Plotting locations on a map

Now that you have two vectors `latitude` and `longitude`, and the corrsponding columns `lat` and `lon` in the data frame `dat`, let's try to plot those coordinates on a map.

A naive option would be to graph the locations with `plot()`:

```{r ugly_map}
plot(dat$lon, dat$lat, pch = 19, col = "#77777744")
```


Althouth the previous call shows the dots with the right latitude and longitude coordinates, there's no visual cues that let us perceive the information in a _geographical_ way.

Instead of displaying a _naked_ `plot()`, we can use the package `"RgoogleMaps"` which is one the several packages available in R to plot maps.

```{r}
# install.packages("RgoogleMaps")
library(RgoogleMaps)
```

To get a map you use the function `GetMap()` which requires a `center` and a `zoom` specifications. The `center` is a vector with the latitude and longitude coordinates. The argument `zoom` refers to the zoom level.

```{r san-francisco, echo = FALSE}
# coordinates for center of the map
center <- c(mean(dat$lat, na.rm = TRUE), mean(dat$lon, na.rm = TRUE))

# zoom value
zoom <- min(MaxZoom(range(dat$lat, na.rm = TRUE), 
                    range(dat$lon, na.rm = TRUE)))

# san francisco map
map1 <- GetMap(center=center, zoom=zoom, destfile = "lab11-images/san-francisco.png")
```

```{r eval = FALSE}
# coordinates for center of the map
center <- c(mean(dat$lat, na.rm = TRUE), mean(dat$lon, na.rm = TRUE))

# zoom value
zoom <- min(MaxZoom(range(dat$lat, na.rm = TRUE), 
                    range(dat$lon, na.rm = TRUE)))

# san francisco map
map1 <- GetMap(center=center, zoom=zoom, destfile = "san-francisco.png")
```

The code above downloads a static map from the Google server and saves it in the specified destination file. To make a plot you have to use `PlotOnStaticMap()`

```{r san-francisco-map}
PlotOnStaticMap(map1, dat$lat, dat$lon, col = "#ed4964", pch=20)
```

-----

## Maps with `"ggmap"`

Another useful package for plotting maps is `"ggmap"`. As you may guess, `"ggmap"` follows the graphing approach of `"ggplot2"`.

As usual, you need to install the package:

```r
# remember to install ggmap
install.packages("ggmap")
library(ggmap)
```

It is possible that you run into some issues with `"ggmap"` (and `"ggplot2"`). Apparently, there are a couple of conflicting bugs in some versions of these 
packages. If you encounter some cryptic errors, you may switch to an older version of `"ggplot2"`

```r
# skip this part (come back if you run into some error messages)
# (go back to a previous version of ggplot)
devtools::install_github("hadley/ggplot2@v2.2.0")
devtools::install_github("dkahle/ggmap")
```

Here I'm assuming that the data frame `dat` already includes columns `lat` and `lon`:

```r
# add variables 'lat' and 'lon' to the data frame
dat$lat <- latitude
dat$lon <- longitude
```

Because some rows have missing values in the geographical coordinates, we can get rid of them with `'na.omit()`:

```{r}
# let's get rid of rows with missing values
dat <- na.omit(dat)
```

In order to plot a map with `ggmap()`, we need to define the region of the map via the function `make_bbox()`:

```{r}
# ggmap typically asks you for a zoom level, 
# but we can try using ggmap's make_bbox function:
sbbox <- make_bbox(lon = dat$lon, lat = dat$lat, f = .1)
sbbox
```

Now that you have the object `sbbox`, the next step is to get a map with `get_map()`. This function gets a map from Google by default.

```{r}
# get a 'terrain' map
sf_map <- get_map(location = sbbox, maptype = "terrain", source = "google")
```

Having obtained the `sf_map` object, we can finally use `ggmap()` to plot some dots with our `lat` and `lon` coordinates:

```{r sf_map}
ggmap(sf_map) + 
  geom_point(data = dat, 
             mapping = aes(x = lon, y = lat), 
             color = "red", alpha = 0.2, size = 1)
```

-----

## Let's look for specific types of food

The data table `dat` contains a column `optionaltext` describing the types of food and meals served by the food trucks. Let's take a look at the first 3 elements:

```{r}
dat$optionaltext[1:3]
```

Notice that the first element (i.e. the first food truck) prepares _Tacos, Burritos, Tortas, Quesadillas_, etc.

What if you want to identify all locations that have burritos? This is where regular expressions comes very handy. Again, always start small: select the first 10 elements of `optionaltext`

```{r}
foods <- dat$optionaltext[1:10]
```

- Use `str_detect()` (or equivalently `grep()`) to match `"Burritos"` and `"burritos"`.
- If you use `grepl()`, you can use `ignore.case = TRUE` to match for both.
- Try another pattern: e.g. `"tacos"`, or `"quesadillas"`
- Now create a data frame `burritos` by subsetting (i.e. filtering) the data frame to get only those rows that match `"burritos"`
- Use the `lat` and `lon` corrdinates in `burritos` to display a map of locations with _burritos_ (see map below).
- Experiment with other types of foods
- Challenge: try use facetting to show a type of food per facet (e.g. one facet for burritos, another for quesadillas, another one for tacos, etc)

```{r sf_map_burritos, echo = FALSE, warning = FALSE}
burros <- grepl("burritos", dat$optionaltext, ignore.case = TRUE)
burritos <- dat[burros, ]

ggmap(sf_map) + 
  geom_point(data = burritos, 
             mapping = aes(x = lon, y = lat), 
             color = "blue", alpha = 0.2, size = 1)
```


-----


## Practice more Regex patterns

Here's a vector with some character strings:

```{r}
# vector of strings
animals <- c('dog', 'cat', 'bird', 'dolphin', 'lion',
             'zebra', 'tiger', 'wolf', 'whale', 'eagle',
             'pig', 'osprey', 'kangaroo', 'koala')
```

Let's match the pattern `dog` with `grep()`

```{r}
grep('dog', animals)
```

To _extract_ the matched pattern, you can use `grep()` with the argument `value = TRUE`:

```{r}
grep('dog', animals, value = TRUE)
```

Using `"stringr"` functions, you can use `str_detect()` to check if there is a match:

```{r}
#library('stringr')
str_detect(animals, 'dog')
```

To extract the matched pattern, you use `str_extract()`:

```{r}
str_extract(animals, 'dog')
```

What if you just want to extract the matched pattern and nothing else? Then use logical subsetting:

```{r}

```


### Your turn

Use `str_extract()`, and logical subsetting with `str_detect()`, to find the names of animals with:

- zero or more `o` 
- zero or one `o`
- at least 1 `o`: `"dog" "dolphin" "lion" "wolf" "osprey" "kangaroo" "koala"`
- exactly 2 `o`'s together: `"kangaroo"`
- one `o`, but not two `o`'s together: `"dog" "dolphin" "lion"    "wolf" "osprey"  "koala"`
- two vowels together: `"lion" "eagle" "kangaroo" "koala"`
- two consonants together: `"bird" "dolphin"  "zebra" "wolf"     "whale" "eagle" "osprey" "kangaroo"`
- three consonants together: `"dolphin" "osprey"`
- three letters only: `"dog" "cat" "pig"`
- four letters only: `"bird" "lion" "wolf"`

```{r}
# zero or more 'o'
str_extract(animals, 'o*')
animals[str_detect(animals, 'o*')]

# at least 1 'o'
str_extract(animals, 'o+')
animals[str_detect(animals, 'o+')]

# zero or one 'o'
str_extract(animals, 'o?')
animals[str_detect(animals, 'o?')]

# exactly 2 'o'
str_extract(animals, 'o{2}')
animals[str_detect(animals, 'o{2}')]

# animals with one `o`, but not two `o`'s together
str_extract(animals, 'o[^o]')
animals[str_detect(animals, 'o[^o]')]

# two vowels together
str_extract(animals, '[aeiou]{2}')
animals[str_detect(animals, '[aeiou]{2}')]

# two consonants together
str_extract(animals, '[^aeiou]{2}')
animals[str_detect(animals, '[^aeiou]{2}')]

# three consonants together
str_extract(animals, '[^aeiou]{3}')
animals[str_detect(animals, '[^aeiou]{3}')]

# names with three letters
str_extract(animals, '^[a-z][a-z][a-z]$')
str_extract(animals, '^[a-z]{3}$')
animals[str_detect(animals, '^[a-z]{3}$')]

# names with three letters
str_extract(animals, '^[a-z][a-z][a-z][a-z]$')
str_extract(animals, '^[a-z]{4}$')
animals[str_detect(animals, '^[a-z]{4}$')]
```
-----

## File Names

Here's another character vector with some file names and their extensions:

```{r}
files <- c('sales1.csv', 'orders.csv', 'sales2.csv',
           'sales3.csv', 'europe.csv', 'usa.csv', 'mex.csv',
           'CA.csv', 'FL.csv', 'NY.csv', 'TX.csv',
           'sales-europe.csv', 'sales-usa.csv', 'sales-mex.csv')
```

### Your turn

- Find the file names containing numbers
- Find the file names containing no numbers
- Find the file names containing lower case letters
- Find the file names containing upper case letters
- Find the file names containing a dash
- Find the file names containing no dash
- Create a vector of files by replacing the 'csv' extension into 'txt' extension
- Separate file name from file extension
```{r}
# file names with numbers
grep('[0123456789]', files, value = TRUE)

# equivalently (file names with numbers)
grep('[0-9]', files, value = TRUE)

# equivalently (file names with numbers)
grep('[[:digit:]]', files, value = TRUE)

# file names with no numbers
grep('.\\D.csv', files, value = TRUE)

# equivalently (file names with no numbers)
grep('.[^0-9].csv', files, value = TRUE)

# file names with lower case letters (including file extension)
grep('[a-z]', files, value = TRUE)

# file names with lower case letters (just the name in lower case)
grep('[a-z].csv', files, value = TRUE)

# file names with lower case letters (just the name in lower case)
grep('[[:lower:]].csv', files, value = TRUE)

# file names with upper case letters
grep('[A-Z]', files, value = TRUE)

# equivalently (file names with upper case letters)
grep('[[:upper:]]', files, value = TRUE)

# file names containing a dash
grep('-', files, value = TRUE)

# file names containing no dash
grep('^[^-]*$', files, value = TRUE)

# changing 'csv' extension into 'txt' extension
sub('csv', 'txt', files)

# separate file name from file extension
# (we need to escape the dot character)
strsplit(files, '\\.')

```
-----

## Some Functions

Create a function `split_chars()` that splits a character string into one single character elements. The output must be a single character vector. For example, `split_chars('Go Bears!')` should return

```
"G" "o" " " "B" "e" "a" "r" "s" "!"
```
```{r}
# Create a function split_chars() that splits a character string 
# into one single character elements.
split_chars <- function(x) {
  unlist(strsplit(x, ''))
}

split_chars('Go Bears!')
split_chars('Lumox Maxima')
```

Here's another exmaple, `split_chars('Expecto Patronum')` should return:

```
"E" "x" "p" "e" "c" "t" "o" " " "P" "a" "t" "r" "o" "n" "u" "m"
```

Write a function `reverse_chars()` that reverses a string by characters. For instance: `reverse_chars("gattaca")` should return

```
"acattag"
```

and `reverse_chars("Lumox Maxima")` should return

```
"amixaM xomuL"
```
```{r}
# Write a function reverse_chars() that reverses a string by characters. 
reverse_chars <- function(string) {
  string_split <- strsplit(as.character(string), split = "")
  reversed_split <- string_split[[1]][nchar(string):1]
  return(paste(reversed_split, collapse = ""))
} 

reverse_chars("Lumos Maxima")
reverse_chars("expecto patronum")
```